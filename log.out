Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f5bf2539-e226-4ab3-af9a-0c7526fafd00
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-bf7e44cf-d5cc-4ec2-acd5-adc9792d67ce
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-7cd66648-18ce-427b-bcd3-4db7dad3921f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-177fc950-68f9-491d-974f-eeeaf33b7e8e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b83063f5-a3d7-444e-bb29-4ad92f080f6e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-43f85885-8a15-4cbb-b2f2-55fea83037dc
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-c4b4991f-632f-4ee1-adc9-0a593ea7d9a0
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-5723e26b-1886-4516-b6d2-4a4584265025
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-7fa782f1-b8e4-4b6f-837b-da9a4f1268f5
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-a4246fc7-f7a9-4dd4-93f3-3a2b7474c032
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-0806419e-4d7e-4f30-aeaf-400a4a0cf8fe
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9804a685-0c06-4545-b925-9c60afd61834
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-8d6266bf-7b26-4c18-ac2d-b09fdada3801
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-5e8f0476-0fb1-4299-aa20-b737583e2143
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-8fcd4b89-8b77-4518-868c-ceca83620db3
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-8a1385fe-36f2-4166-b485-3f1b6aff2d8e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-20f4ad73-008b-411b-9cfd-1ccdb2d21989
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-5072419b-6efc-433e-a761-e3cbe532687d
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-caf34445-b631-4073-9f9d-f084e4b0d4a3
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3f2252b7-da82-46a1-bc99-60ca9d78867b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-0325f000-906e-43dc-a6f0-21f0db62089c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-59d5a690-26ec-4dd5-b2f0-bd9ff1ba118b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-90da73f6-0ded-4faa-97c3-8888aa30970f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f186f588-a840-4c72-bb5f-ef2e667f5091
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-14670868-09e0-41b6-a945-862c9f87a374
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-703a6cbd-c808-4bfb-bbe4-95fea4170daa
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-1847b6cd-ba94-4d29-883e-4714240c12f9
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-02822be2-4161-4b84-b532-737d53d37a29
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-321e60dc-d0b9-47ca-8bb1-68c7fa8d48f2
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-91d4525f-999a-40e0-ab25-553fffff600d
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-5a6bf3b9-eeae-4e93-8325-2f157c4247a2
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b5da0866-ee2c-47e0-be3f-21a51ccce4d0
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-2ca07306-c15c-47ab-8dd8-6574a14ea2f5
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-547615c6-939e-40c2-b703-23e1448ea467
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-6a70c2b4-d457-47c1-8265-a299b2c23790
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-93dfc3d9-b932-4a13-87c1-d81512773d71
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-a2520fd0-e6a9-460b-84c0-289bca3611ae
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-bf696d1a-157e-4f5f-8892-57ded9facf02
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f5aab33a-8269-4a74-b223-ec0c0aea8997
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-4050c75e-0b66-492c-bd0a-7723dc40fc00
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-0edc50ad-eec1-45b2-84bc-9d6e43e2c352
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-6c52251c-cb44-4f49-b399-848d0db7cb3c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9c421b20-c64f-447c-8c0a-c40e0e8f74c5
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9298b4d6-46c5-4ba7-9bc3-2dbc393fbd07
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b9965c8b-d152-42c1-9355-665e29c07538
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-52fa418f-b124-4787-8967-7d3f7f9fcaba
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9b8ed643-69e9-4b57-af99-4100a198ea46
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-d1a6788f-fa93-4050-b0c5-e74b43252947
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-bc1008e9-93ed-488b-ae01-4ed79525c099
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-d28b8fc8-bdf1-4ab3-974e-d7b8261998fb
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-5eef8d58-1e16-4267-879e-1d9b523692bd
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-bc17cca2-71d4-4f61-a304-c7b6f939f606
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-befb596c-9fb1-459c-9722-72b28b52b50a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-8924dead-869c-48fc-bb9d-ef934ba50880
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-54a34d42-f68b-4b4b-90b9-062724281f1c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-0a17ccc1-7512-48a5-b87e-bf537bda608c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-1d07994b-8c67-49ca-aa34-a80003524320
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f1bac3d9-b1f4-416f-88dc-c9e22e8c8ac3
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-bd247347-c1f3-4bee-bc88-c84f358d333d
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e3d88fcc-d2e0-47c8-9f8a-7387521b29e3
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-805b461d-a7c3-43d9-bb2a-823189509337
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-cf6a0988-996c-4d24-bb13-af6613410c89
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e44d21c8-c752-4079-9b27-1af9f8301eda
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9f7697be-93cc-4b9a-a9f5-23a49404267a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-58c49823-5229-4260-b1d3-53f4e85dfa3e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-015ba656-02a7-438f-93d4-d231f7bef2aa
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-8e5d2f29-9f2c-4a1e-9d3d-aa030f66050a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-554e4d1a-e5cc-4c54-8085-bfc820fa4fa5
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f68ef2eb-ad76-43b1-ae94-d8c9cca4f5ed
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-974437ec-428f-45b9-a20b-b99fca425d3b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-da05df52-0088-45c1-92da-07c76dff064f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-27d2ec7f-cb18-40dd-89d8-aff80deaa4bb
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-da1ab970-f972-4ccc-a4d1-9be4a0d3785a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-aa0dc7cb-1ad2-486a-a9bd-c895c67021bf
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-db4e01bf-0fc8-497a-8a28-cc803743154d
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3ad16cdc-1cd4-4008-b175-e5e97ce4fcd9
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-aca9c9b5-7a37-47b7-847f-1542ae8c0fc0
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f8b78d21-45ea-4b9e-bc67-8b06e3a5d9de
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-2f566afb-2f11-4fa9-a692-f6ba0c3343c9
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b95d290b-56a8-46b3-8911-167b2d61dd1d
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3d9606ad-6bf1-4d2c-b68a-c3737fc0557a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-70ab2eb4-a626-459a-aa83-1f91e7370184
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-c4e4297a-2d51-495b-8293-a6435f44b94d
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e2d9759c-04ad-47ed-9bbb-f5723571c92f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-48c0a396-2411-43c0-8fbb-f24cd7eeb0a9
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-8989e03d-912f-4ea8-befa-ecbe78db8942
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b40b9f0d-b252-4789-9201-3858aff85bd8
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b4ad34ab-0fbf-4cb9-8e6d-521d9211db34
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e72c215b-d8e1-45b6-9e06-387dca774f40
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-78611f9a-0b9a-410e-8d5e-c6af9d6eed7c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-cab0b00d-1fb0-4074-9309-db9bad585161
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-18e0b7e9-ac9b-4fa4-a326-663aea968835
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-d6da64d1-1b2b-41f5-a5bd-1c28cfb4ca0a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-6b243a6d-ecef-4222-a819-0e7cca806cd5
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-600cbf9d-345a-4bee-9873-be042f3571d0
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e294ede5-aa09-4b8a-9078-9cf804d5c058
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-35193fb8-b1ee-4889-9ccf-3f3f66264d5b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-0439de38-6885-4563-b418-edb213af88b6
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-194dbeb7-40f8-4d9b-97c2-bd05a4537bd3
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-a0111bdd-a656-4054-a908-9656c5153c14
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-0c8bd74d-9b10-473c-82a7-c652c235b309
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3c5ae5a3-2650-4741-a6d0-e5aca8b725fe
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-21aee2ca-aee5-4e9e-9124-3ac5df5d2d16
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-a7331315-f28f-4bc5-8c09-acba171efdff
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-33f253ca-d677-4574-a261-43746f909970
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-eeb7e721-1c72-48d3-958f-b09bfa430277
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-79f41c9b-4092-492f-aeb4-395136c6d21b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f98a3b02-a60f-4d95-9ff5-24f713902874
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3156b5da-0528-4b98-90b5-3728ace21e72
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b9b97731-0b76-417e-add6-6307c6638842
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-801e0ea4-587c-47fc-bf75-4b808170b237
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-082375e0-ea0b-476c-829b-292da0bfe2fa
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f443355e-6e8a-4d04-af92-8e0168ce4c3c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9ef25065-1a86-49b3-b4ab-135b6731922f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-1fe37e11-0da3-4eca-9825-57e680c2b7e2
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b9705074-2d51-4aca-a817-0dad05fa3228
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9e2e0340-a330-4927-8d39-afa6f2dea301
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-249c3d9c-be70-4d83-a5ab-17bdef83f8af
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-2dd19322-f781-4e9c-824f-50e6c5ac2dae
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-19a9260d-a766-477b-ac42-8ed17d6319ad
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b486c2f3-df0d-4dbd-bbd2-79bf207b5d8b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-41246c31-36ed-4d3b-b6c1-db5588d77ae5
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-35cb9fa4-7902-4bc5-bacb-668f686c92c2
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-c4d98463-54c5-483f-886c-0958658aaad8
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 63001.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-e51ecfbc-7b7d-40d3-b890-09979b70ee90
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @25384ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @25668ms
Started ServerConnector@237c43e2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@1e22fa70{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@38d94e69{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@57cb527f{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@39cf4ed2{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4b97f584{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@46420e23{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e4c276f{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7f1c8657{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@94a184{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6fd0193f{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@bff01c6{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@104a10d0{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@35f71bdc{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a01f5bc{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@29033e0b{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@690f776b{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@642ba86d{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@31d21d41{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1918e16{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@13370560{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2a66bfab{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@597d87f{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@682e04a7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@338a619f{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@982b6f5{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63022.
Server created on DESKTOP-GGEMGVJ:63022
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63022, None)
Registering block manager DESKTOP-GGEMGVJ:63022 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 63022, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63022, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 63022, None)
Started o.s.j.s.ServletContextHandler@20c7d561{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@54340152{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2c0718{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@cf7fa9d{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5e65c0b8{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@764b9943{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@237c43e2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-d404ebca-b9bf-43c5-b94f-9813cffe9b5d
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-a0ea98f7-dd9e-4ad0-a93f-b91c62d5839c\pyspark-c407ff07-7bb0-4e73-b20f-14c1b7c925bb
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-a0ea98f7-dd9e-4ad0-a93f-b91c62d5839c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 63053.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-8e140577-ae36-4a05-83cf-d92699bda5cc
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @24681ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @24819ms
Started ServerConnector@c3cdd04{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@7a276f5a{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fd74e57{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5b3abbdc{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@15837b3e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@30832a2f{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3ee983b8{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@547de1ce{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1d4185d{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a1cea38{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@29f18915{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4f4b8136{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6e7c6e72{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@33ec04af{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16f08ae6{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5a1fb3f{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@8230a07{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5b39aed0{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@490cb8eb{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@437edaf6{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@539d83ac{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4544e821{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@45951e5a{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7ffc2ac7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@35754712{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5be6191a{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63075.
Server created on DESKTOP-GGEMGVJ:63075
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63075, None)
Registering block manager DESKTOP-GGEMGVJ:63075 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 63075, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63075, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 63075, None)
Started o.s.j.s.ServletContextHandler@3b6a011f{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@25a3c501{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@16e62ca7{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@37fbb68{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@515eb07c{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71fa0433{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@c3cdd04{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-91ad298a-4c01-4473-a975-376e7c960a27
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-91ad298a-4c01-4473-a975-376e7c960a27\pyspark-34f018ef-cef1-44d3-abb3-692a464e6378
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-83b210e5-5c5b-4d9b-8ce3-efcbabef7354
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 63119.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-3bdfb86f-3ddd-475e-ab14-06c6dca5c5a6
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @25202ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @25333ms
Started ServerConnector@6ae47fd5{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@77ba0119{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@53459a4f{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7d933fb8{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17b5960e{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@685de155{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@cd77d19{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2edcffa4{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25ba9ddd{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6c526711{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@697975ad{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6be04e88{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1a45725c{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6550f4ea{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@472631f0{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2e5bb392{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fbdf397{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7da8a32e{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@bf7a4da{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@78c34115{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@81234d1{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@301b572e{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@623b432d{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a4e85c4{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6007b6f6{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2692834{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63140.
Server created on DESKTOP-GGEMGVJ:63140
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63140, None)
Registering block manager DESKTOP-GGEMGVJ:63140 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 63140, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63140, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 63140, None)
Started o.s.j.s.ServletContextHandler@51fce412{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@5f8a3d09{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@331d7eac{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@24c42811{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5d19d2c3{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6230c402{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@6ae47fd5{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e2a8653a-6faa-48e1-a68d-853a5f92cc08
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e2a8653a-6faa-48e1-a68d-853a5f92cc08\pyspark-c05b3089-e8a1-45c0-83cc-b94d67623332
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-d65da791-0748-458c-9071-a699675fb361
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 63166.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-1cf165d7-5e5a-4967-aca6-83d1d038670f
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @25433ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @25549ms
Started ServerConnector@7786dd78{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@69a889f5{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1f4df840{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6c51f3e0{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7973094{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@776857de{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@14c57420{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@275abda9{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@13cf4dc7{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@618a0de2{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@418fbe9f{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4fd5227f{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@261dff37{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1749030b{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2b0e2c3b{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4d2e25ff{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4038f2a{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5b8d95fa{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1380544{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3d05c941{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25e77b14{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@12f21817{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@48d53028{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3644f5dd{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@648a51ca{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@41a4aae2{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63187.
Server created on DESKTOP-GGEMGVJ:63187
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63187, None)
Registering block manager DESKTOP-GGEMGVJ:63187 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 63187, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63187, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 63187, None)
Started o.s.j.s.ServletContextHandler@43e716e9{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@5ef4c41d{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65997f78{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a3751b9{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3c5dd260{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@252afd17{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@7786dd78{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-2da81e80-4172-4be4-9430-2e06e94bbdbe\pyspark-7301133a-79e6-495e-9208-ffed9c31001f
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-6bd8a31b-31ab-4b6b-a314-b7c9f2717ca4
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-2da81e80-4172-4be4-9430-2e06e94bbdbe
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 63215.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-37278b92-a5db-4690-8bb5-c9b31a3ef809
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @27188ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @27371ms
Started ServerConnector@46e36dc2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@610bc070{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@29cb5c76{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6544ed3e{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1a284e06{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69f399d9{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2b1ca4c4{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a04b35d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@59384e14{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@46399035{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@e8a53d{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7041f697{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6b124e65{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6120d30a{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@24a4535e{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5baeec13{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@22b6f065{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4569dfba{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43515aea{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6f33f8e7{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7a1318bc{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@710c8c4b{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69d4886c{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@58fa5a2b{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1f26106a{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1012aedf{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63237.
Server created on DESKTOP-GGEMGVJ:63237
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63237, None)
Registering block manager DESKTOP-GGEMGVJ:63237 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 63237, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63237, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 63237, None)
Started o.s.j.s.ServletContextHandler@3b2266db{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@7550aa66{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@ca84866{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3c57cf5a{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4d18d20{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@674b80f4{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@46e36dc2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-a1f54791-0033-4218-9a31-291d0127c790
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-36f6864f-26f8-4234-8762-06a4f863a15f\pyspark-0c522f6d-ac87-480f-80c2-f2cd6879392d
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-36f6864f-26f8-4234-8762-06a4f863a15f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 63951.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-1d818d81-3191-4631-a24b-0aadc4286341
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @24920ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @25079ms
Started ServerConnector@2223c4ce{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@2e4fb278{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2fd60154{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1e4617c8{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4c86ee2a{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@53459a4f{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7d933fb8{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6c39d21d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@cd77d19{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2edcffa4{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@15621997{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@12b21527{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25ba9ddd{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6c526711{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@697975ad{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6be04e88{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1a45725c{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6550f4ea{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@472631f0{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2e5bb392{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1fbdf397{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7da8a32e{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6e88c500{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3816f89{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a4e85c4{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@157eee4c{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63972.
Server created on DESKTOP-GGEMGVJ:63972
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63972, None)
Registering block manager DESKTOP-GGEMGVJ:63972 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 63972, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 63972, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 63972, None)
Started o.s.j.s.ServletContextHandler@611ad43b{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@33c82105{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3b21e60b{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@68a09b77{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3bbae7f8{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7218d802{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@2223c4ce{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-05a009f7-b57c-43ba-85a2-d2eac5269ceb\pyspark-ff7071ff-412f-4a53-90b2-13eb3c633071
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-05a009f7-b57c-43ba-85a2-d2eac5269ceb
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-18d3ab83-e4c9-4886-bf18-ee14a019c30a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 64133.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-5b4a2f61-3d37-4351-ba09-da7bfee0b759
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @26995ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @27138ms
Started ServerConnector@298fbe8b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@4f24f736{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@730862d{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5ad9d605{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@68d2049d{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6bd0f644{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7fad7cc5{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6df43bf4{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6dab8ab9{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@214c2763{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6593cc85{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@38eade9b{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@9a5657d{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49923c15{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@321e3646{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5c6e3898{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7e4220e5{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2668c9ac{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65876721{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@488039f1{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@27aa6d0c{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@47eff5fc{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@723f58e1{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4118b292{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@d6f654b{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5d80ff85{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64155.
Server created on DESKTOP-GGEMGVJ:64155
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64155, None)
Registering block manager DESKTOP-GGEMGVJ:64155 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 64155, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64155, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 64155, None)
Started o.s.j.s.ServletContextHandler@6337dda{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@674ef30{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10da4949{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1125d6db{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@14c05de2{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3fb7a1e9{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@298fbe8b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-93dc9c98-96ec-4a4a-9692-64ed72d519f0
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-40b9d58f-211b-4099-b0be-a51490f698c4
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-93dc9c98-96ec-4a4a-9692-64ed72d519f0\pyspark-bc624c32-7068-4467-ae89-2b470efc7e77
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 64233.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-4e9c5dd0-a08b-40ee-a528-6fb644e632e1
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @30373ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @30630ms
Started ServerConnector@3ac0ac12{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@5df5b747{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@669c9930{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2d50789e{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@51c953b7{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@539e05a7{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7d2403c2{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@370fd70d{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@52b7dd89{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1bc9cf6d{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@34d3075a{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3ca69917{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5091409f{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5764f47{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@29336164{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@21d52b74{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7b1a1269{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4c21763a{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7eab169b{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@762d1cb1{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5d8fc147{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1ad8fc6a{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@90fdc45{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6682e0fa{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6ae0331d{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@15b16a53{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64254.
Server created on DESKTOP-GGEMGVJ:64254
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64254, None)
Registering block manager DESKTOP-GGEMGVJ:64254 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 64254, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64254, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 64254, None)
Started o.s.j.s.ServletContextHandler@2fe14fa6{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@61bc6fc7{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@50d4e666{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1f745d2c{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1ed02de5{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71a5a719{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@3ac0ac12{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9bc0455f-baa1-418d-9e72-ad99a909005a
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-da8d3fb9-ed43-4038-b76b-906995996a64
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-da8d3fb9-ed43-4038-b76b-906995996a64\pyspark-9cdc15f1-53af-44f3-b2bd-b777af97fbbc
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 64390.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-ed9763a4-8c9e-43d7-8a24-cb866350d71e
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @26784ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @26926ms
Started ServerConnector@2e106f58{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@16832156{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@10f0148a{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1d62902e{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@28d3ec0d{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3897e9d9{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@317dfd05{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6e34a5b3{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@a5372f{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4bf703b5{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1665ba58{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3bc75b5a{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@12720f42{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@61eb5c12{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5ae78d0d{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5bfb1080{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@59f10ca2{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6241c042{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4a8b6e2{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@754c9e7{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@561141b3{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3abec8e3{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@17ccd48c{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5e67cd4a{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1f76aca6{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@52f49dc2{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64411.
Server created on DESKTOP-GGEMGVJ:64411
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64411, None)
Registering block manager DESKTOP-GGEMGVJ:64411 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 64411, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64411, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 64411, None)
Started o.s.j.s.ServletContextHandler@3617bb0f{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@3bc6dfbd{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2bf627{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@71ed9c41{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4d6af7f8{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@24ef197{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@2e106f58{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ee3d9e82-8698-408c-8517-1fc82b6ce3b3
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-42453d83-9f9f-4bf7-b998-5a27356f1051
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ee3d9e82-8698-408c-8517-1fc82b6ce3b3\pyspark-e75a7b25-5602-42c4-b26e-a24d9eff0727
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 64454.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-33131716-542b-4887-8989-2d6709c42a34
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @26170ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @26321ms
Started ServerConnector@caea50{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@37718479{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6544ed3e{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@251683f1{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69f399d9{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2b1ca4c4{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3a04b35d{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@62848265{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@46399035{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@e8a53d{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7041f697{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6b124e65{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6120d30a{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@24a4535e{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5baeec13{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@22b6f065{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4569dfba{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@43515aea{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6f33f8e7{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7a1318bc{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@710c8c4b{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@38c31e8a{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@58fa5a2b{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@624daec7{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1012aedf{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2286b50e{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64475.
Server created on DESKTOP-GGEMGVJ:64475
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64475, None)
Registering block manager DESKTOP-GGEMGVJ:64475 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 64475, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64475, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 64475, None)
Started o.s.j.s.ServletContextHandler@7a145387{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@ca84866{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2da2b39b{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@4d18d20{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@881aa77{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@15616741{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@caea50{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-99158413-650d-4caf-afdb-73128b43a2c9
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-399039fc-bab2-4863-a10d-cfa5141a8dda
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-399039fc-bab2-4863-a10d-cfa5141a8dda\pyspark-5fd63071-d4fb-43e5-8006-eec7a44fb5bc
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 64554.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-e32983b6-d4f9-4e20-a261-cfece699f1d9
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @32208ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @32393ms
Started ServerConnector@3d7ed3bb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@54d890f9{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7e51bc24{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@730862d{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1b912b57{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@68d2049d{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6bd0f644{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7fad7cc5{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@79749a06{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6dab8ab9{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@214c2763{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6593cc85{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@38eade9b{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@9a5657d{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@49923c15{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@321e3646{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5c6e3898{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7e4220e5{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2668c9ac{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@65876721{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@488039f1{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@27aa6d0c{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@da20e26{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@723f58e1{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@967dad7{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@d6f654b{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64575.
Server created on DESKTOP-GGEMGVJ:64575
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64575, None)
Registering block manager DESKTOP-GGEMGVJ:64575 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 64575, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64575, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 64575, None)
Started o.s.j.s.ServletContextHandler@77106b84{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@708b3a52{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@674ef30{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@53775dfd{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1125d6db{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7f5b305a{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@3d7ed3bb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ce5f46d8-8321-4548-815a-53b15a659350\pyspark-1b55e4fb-2be6-403d-8e65-9d3fe284e0dc
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ce5f46d8-8321-4548-815a-53b15a659350
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-020064b2-db3d-442b-b970-758a6a367e1e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Running Spark version 2.4.3
Submitted application: 
Changing view acls to: Probook6570b
Changing modify acls to: Probook6570b
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Probook6570b); groups with view permissions: Set(); users  with modify permissions: Set(Probook6570b); groups with modify permissions: Set()
Successfully started service 'sparkDriver' on port 64612.
Registering MapOutputTracker
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at C:\Users\Probook6570b\AppData\Local\Temp\blockmgr-7ce0329b-3a48-4585-94e6-249365711e23
MemoryStore started with capacity 366.3 MB
Registering OutputCommitCoordinator
Logging initialized @27152ms
jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
Started @27266ms
Started ServerConnector@42e39014{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
Started o.s.j.s.ServletContextHandler@3da6ef94{/jobs,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6cc94c37{/jobs/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2c084210{/jobs/job,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@77955596{/jobs/job/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@519b07a7{/stages,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3f6dc746{/stages/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@25d33490{/stages/stage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@209ed445{/stages/stage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@1c550372{/stages/pool,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5b477185{/stages/pool/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@69bbe678{/storage,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3fd12bf6{/storage/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@b2bf1ed{/storage/rdd,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6b807254{/storage/rdd/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@5dbec17a{/environment,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6b86dfa0{/environment/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3ff6ffa4{/executors,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@570c38dc{/executors/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@7c128656{/executors/threadDump,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@21b42dab{/executors/threadDump/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2937ede6{/static,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6105d88d{/,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@764db1{/api,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@46b3a524{/jobs/job/kill,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@6a56764f{/stages/stage/kill,null,AVAILABLE,@Spark}
Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-GGEMGVJ:4040
Starting executor ID driver on host localhost
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64633.
Server created on DESKTOP-GGEMGVJ:64633
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64633, None)
Registering block manager DESKTOP-GGEMGVJ:64633 with 366.3 MB RAM, BlockManagerId(driver, DESKTOP-GGEMGVJ, 64633, None)
Registered BlockManager BlockManagerId(driver, DESKTOP-GGEMGVJ, 64633, None)
Initialized BlockManager: BlockManagerId(driver, DESKTOP-GGEMGVJ, 64633, None)
Started o.s.j.s.ServletContextHandler@71991638{/metrics/json,null,AVAILABLE,@Spark}
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse').
Warehouse path is 'file:/C:/Users/Probook6570b/Documents/School/web%20and%20social/web%20and%20social/spark-warehouse'.
Started o.s.j.s.ServletContextHandler@358128a3{/SQL,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@881fa28{/SQL/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@3c0489ef{/SQL/execution,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@f2d7c0f{/SQL/execution/json,null,AVAILABLE,@Spark}
Started o.s.j.s.ServletContextHandler@2ae76e04{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
Invoking stop() from shutdown hook
Stopped Spark@42e39014{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Stopped Spark web UI at http://DESKTOP-GGEMGVJ:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-1f1c68e7-c9a3-4bf2-b68a-3f05d525329c\pyspark-00497dc2-d29b-440f-bfa4-e02d0ea2cddd
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e9e12265-ad2c-4a71-bdca-2920fb3e27ac
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-1f1c68e7-c9a3-4bf2-b68a-3f05d525329c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-322cac16-6550-448f-9684-f48e54168d70
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-80c0043d-b396-411b-8714-86bd825106aa
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-28b5bc7a-a280-41e3-8820-b7c5790c7544
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ecd324fb-6145-444f-a725-2a139e621974
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-24463bbc-8b64-4e27-ae47-38692d9fbe32
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-bab3097d-3771-4cf4-a2ea-224186338e81
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-94b7d233-4119-4fea-8c54-9c579b3225e3
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-443fa8d7-9db0-47c1-b316-505b181d9a97
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-0ed8951c-8188-4072-a50b-cf0f179126ce
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f5ee1aaa-0e80-4edf-9054-346a91f9d9ee
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-029aa7ee-67d7-43c8-8a59-fe8ef7dfeea0
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-93e9d98d-d459-42a7-a845-97fa7e19953c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f19f4c19-fb3c-4553-9b39-f108397cd700
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3f7dfe05-e8c0-4afd-aaa2-3ed8e0c31bcc
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-2946d51c-e9f1-40fd-8726-d777bd04cf9b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-31b6fcd8-0b6c-49b9-9ddc-ecb7dd8c77eb
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-aa1bcd99-744b-4f9b-9a3a-799fa0a796d0
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-aeaa6e11-ca49-4dfd-9666-8ae1094e636e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-59fd42e6-3fc6-4b07-96b8-b3c41926ec7b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-03eb3ddf-d7fe-4fcc-ae3c-22f6e9d34f03
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9f8cad47-bd9b-40f2-b09e-90595c80e3d0
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e2d0c7be-2d42-420b-a328-991cc07d7a9a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-384ada51-494e-445d-83ff-cf0d33daca80
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-01c0d190-3781-4abc-ae37-42589dd75a1b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-648dc2d5-783d-4c74-9dcb-816dc2c43448
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-51c4f7ae-7fc1-4ed8-a512-902d1cc2a1b9
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-5636d523-62dc-4b08-a95d-ef61201dd766
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-0ae3f820-e6f9-4e23-95cc-8e4575f29561
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-898b92a5-f0aa-45e4-a15d-d0f262a84188
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-d609ae91-f950-4812-aa32-69cd3842d2db
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-bc51bb3a-6672-40fc-95d1-99433c173ae3
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f7773d2b-bfb1-434d-8061-14624ddeb37a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-810ec632-2705-44de-ba33-2a095bf5023f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-4489022e-ddc2-41e5-be1d-c8c17e839a92
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-0295a612-de1c-4437-a6ef-9b5d5db05d2e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-a746c136-a43c-48b4-aa0a-75395bfa72a0
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-89d14aee-791a-4957-9a7c-0abd644443fd
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e30e28c7-14ee-4b42-b687-d11d35ee6251
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ab76e643-e3fb-4d75-b2c4-e8d4959c02ab
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e9493ea7-5a0b-40d7-b673-5d97bdf00655
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-81d4fd0a-14b9-4640-bf56-7a29da995f9b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e5f8cfcb-c07b-4f99-909b-260e7c7d41e0
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-494b2053-2560-44cd-a9b2-a5b0092b26af
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-aedb12ff-2a96-4a9e-a63e-c40026acd164
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ad35596a-1838-4abe-850c-5f80d5dace49
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e91f7bca-bf87-4074-906e-a9c6aea6bf14
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-188a19c6-17a5-4cf4-81a9-2bf6fda43916
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3c4d3339-e459-4194-81e5-f24db8f5ade1
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-df96a099-ef53-4d6d-a59f-a43196723b9d
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e815a2a6-f145-4b3d-8772-e12c405db057
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-14e1d610-0859-4986-89ba-73863805b993
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-65691f0b-480c-489f-8389-71d8e2ffd255
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-13dc4a3e-1631-4469-a43c-ce2f0c3160c7
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-fed172d3-0622-4087-a78c-a39a438f7d11
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-657a460d-4a2e-4558-aeca-35ecdfc8225e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-6177ce37-664b-4cf4-896f-a3563d07a16a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-7b8c4f66-b049-4c5f-a730-0e06d6ab9f5f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-144a4b25-f7f7-4e3b-aaa1-8cdc5435cb87
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-312360db-b917-4afc-bb96-9e98fc1ecd21
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3f550879-abca-4ca3-9742-37ecf6bf5c00
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-30fed65a-dab7-4548-8aae-6ce312ad2c05
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9d473cef-26da-4ef6-8ef4-56bffd52ba77
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-64496809-ec0e-45a1-a7db-e5ff739eb844
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-cad65ce0-cfe0-4d48-9f27-97ed6388e075
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-7fa93ae8-fd48-4ce8-967c-c4aa9a94078f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-45ab6a34-492e-44d8-a080-ce5687cb3c07
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f268f68e-055e-435c-b168-3590b0faf024
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-c08c3489-337b-456a-958d-3c4115756566
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-147df92e-0971-4b23-8c35-9b941af86ca2
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-708cd626-7ad8-4d70-a197-49107db59d42
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e142fb1a-4061-4513-8ed2-a604e55d3b35
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-a2208abc-b030-4fec-8ebb-e9b61c2400db
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-cf9e99ec-6787-4bee-9f90-777dc3ea4e96
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-57eec12a-973a-4a03-9618-1347983f452e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-dbf3f4c2-4ea8-404a-8454-664dabcb3c48
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-32e74d78-9020-49c0-851b-56ed534824bc
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ad5eb034-0e38-4ff3-a415-34b57bf2fb53
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-9e5318da-ce24-4a2d-bed6-7babc544195b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f9dace68-d767-4662-80df-a2cf373c7b48
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f4e6d90b-e47c-4df8-ac3b-72b1128ceef4
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-eb3ddc95-7079-43f9-abad-0314b84fbcf3
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-366715a9-c9d3-4d5f-aee7-2ccfb09398b6
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-1906f0a4-ee7b-4420-8420-0e047216e10f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-e91a37b2-3e37-45f5-adf1-25fb1afbee96
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ac39817d-a8dd-4701-971b-8af201b71796
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-fecb954f-0b79-4667-8af0-7dccd9f6cefd
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3f28da9d-d6b5-4327-99aa-ec4f13e928e2
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-821e8ee6-6553-46cb-a1c2-c9c8dc6cd1e2
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-20c2f4b5-f7b9-4aa8-aeca-068582b75f65
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-90f99f0d-42f0-4854-be36-a6c6866d05d3
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ed9aca91-d4ed-4dd7-8827-9938048db32f
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-4db609ab-49cf-4402-8e39-bd65cf7e5df7
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f9e0f797-5343-49f8-8735-70e40b2c7d1a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ac1d3123-2fb2-4aba-9b32-4ef4ae2fcd18
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-c67c0d75-7105-4f3e-ac43-7dd4ec875669
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-3ecac98d-19e8-45ed-aa6c-a8ebe23bff43
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-28d832bc-cfc3-4610-a64e-80085a3ffe4a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-2665c320-4c93-4dea-9afc-94f76c196b33
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-be0b2077-4c65-4892-8bd9-75623003c0bf
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-8fd9f6f5-991f-4c5d-a29d-e3ece1c93360
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-5a0d9b8f-3913-4d8c-ad14-3cd691ce18bc
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-1dae2e0a-9c28-4785-a0ea-23f36311c535
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-c83c793b-7763-4ece-bf54-ac36c3f66ea4
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-91b63056-33fb-45d8-8464-aa5be8638a9d
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-016dcb03-2c7f-44d3-970b-ce9637b8b1e8
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-aab78a75-3897-4b08-8fa8-767c8c8998a4
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-462885f2-187b-41e4-ad2a-225efd4a51b6
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-b3cc5609-988d-44c0-99df-66855a780c61
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-4dc8cbd9-eb2d-4fd5-b18c-ec67a3a47187
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-942f8ad8-4bb9-4571-8b6b-63b1e66b291e
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-226e2513-07cf-4ad4-aefa-4a51412bb849
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-60f5457a-be11-4bce-9e0d-7df111ce91b2
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-dcb06cb1-b1b0-4b68-ad34-c372b2ebac40
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-bc5b7bd2-5d2c-470c-a7ab-09617cb13e81
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-01e526ac-418c-4ec4-b7a2-4edbe6b9260a
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-75460309-204c-4b2a-950e-7416402cce0c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-bcca6b20-b2d4-430d-ac65-0530b751cbeb
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-4a356786-f871-4df2-89be-486411fc4c18
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-f17d2731-df3e-4b8d-8353-0616d19a6d0c
<<<<<<< HEAD
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-4a33435b-70ae-4f60-b44c-865d0ce83e44
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-97c29f23-10e3-4eef-b99d-598709dc914c
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-8a054aeb-8a19-4019-bdf5-af40210b0529
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-595bb43b-decd-4c03-85bf-e2d33b044f17
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-ac57e3ea-aaa7-479d-b788-e8bf70918a7b
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Shutdown hook called
Deleting directory C:\Users\Probook6570b\AppData\Local\Temp\spark-695226f5-8777-4d01-81ac-3619d7202163
=======
>>>>>>> e46e9dcb4fe6e33657ec794c6117870a90b42b3f
